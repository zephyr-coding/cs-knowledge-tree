# Redis

## Redis 常见数据结构以及使用场景分析

### 设置过期

- **string**
    1. **介绍** ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**（simple dynamic string，**SDS**）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。
    2. **常用命令:** `set,get,strlen,exists,dect,incr,setex` 等等。
    3. **应用场景** ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

## 内存回收策略

### 删除过期键对象

1. 惰性删除：惰性删除用于当客户端**读取**带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空。
2. 定时任务删除：
![[Pasted image 20231018002155.png]]

1）定时任务在每个数据库空间随机检查 20 个键，当发现过期时删除对应的键。 2）如果超过检查数 25% 的键过期，循环执行回收逻辑直到不足 25% 或运行超时为止，慢模式下超时时间为 25 毫秒。 3）如果之前回收键逻辑超时，则在 Redis 触发内部事件之前再次以快模式运行回收过期键任务，快模式下超时时间为 1 毫秒且 2 秒内只能运行 1 次。 4）快慢两种模式内部删除逻辑相同，只是执行的超时时间不同。

### 内存溢出控制策略

当 Redis 所用内存达到 maxmemory 上限时会触发相应的溢出控制策略。具体策略受 maxmemory-policy 参数控制。

> 相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，**如何保证 Redis 中的数据都是热点数据?**

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集 (server.db[i].expires) 中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

🤔**记忆方法：一共八种**

清除数据集的范围（内存不足时淘汰）：1️⃣ **volatile** 已设置过期时间的数据集 (expire)。 2️⃣ **allkeys** 数据集（全部）。

清除策略：1️⃣ **lru**(least recently used) 最近最少使用。 2️⃣ **lfu**(least frequently used) 最不常用。 3️⃣**random** 随机。

**以上数据集来源和清除策略组合起来，就是前六种。**

还有两种：

volatile-ttl 已设置过期时间的数据集中挑选**将要过期**的数据

no-eviction 不能淘汰数据。内存不足以写入新数据，新写入直接报错。

## 缓存穿透、击穿、雪崩

### **缓存穿透**

描述：访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下一次同样会打到数据库上。

此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。

**解决方案：**

1. **接口校验。**在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以**这种场景最大的可能性是遭受了非法攻击**。可以在**最外层先做一层校验**：**用户鉴权、数据合法性校验等**，例如商品查询中，商品的 ID 是正整数，则可以直接对非正整数直接过滤等等。
2. **缓存空值**。当访问缓存和 DB 都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要根据产品业务特性来设置。
3. **布隆过滤器**。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。

### **缓存击穿**

描述：某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。

解决方案：

1. **加互斥锁**。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就快速失败返回默认值。
2. **热点数据不过期**。直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。这种方式适用于比较极端的场景，例如流量特别特别大的场景，使用时需要考虑业务能接受数据不一致的时间，还有就是异常情况的处理，不要到时候缓存刷新不上，一直是脏数据，那就凉了。

### **缓存雪崩**

描述：大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力骤增，引起雪崩，甚至导致数据库被打挂。

_缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。_

解决方案：

1. **加互斥锁**。该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程查询失败则快速返回默认值。
2. **热点数据不过期**。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。
3. **过期时间打散**。既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。

## 日志 RDB AOF

### RDB

**触发机制：**

1. bgsave 命令手动触发
2. 自动触发：

- 使用 save 相关配置，如“**save m n**”。表示 m 秒内数据集存在 n 次修改 时，自动触发 bgsave。
- 如果**从节点执行全量复制操作**，主节点自动执行 bgsave 生成 RDB 文件并发送给从节点。
- 执行**debug reload 命令重新加载 Redis**时，也会自动触发 save 操作。
- 默认情况下**执行 shutdown 命令**时，如果没有开启 AOF 持久化功能则自动执行 bgsave。

流程：

![[Pasted image 20231018002248.png]]

1) 执行 bgsave 命令，Redis 父进程判断当前是否存在正在执行的子进程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回。

2)**父进程执行 fork 操作创建子进程，fork 操作过程中父进程会阻塞**，单位为微秒。

3) 父进程 fork 完成后，bgsave 命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令。

4)**子进程创建 RDB 文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。**

5) 进程发送信号给父进程表示完成，父进程更新统计信息。

虽然压缩 RDB 会消耗 CPU，但可大幅降低文件的体积，方便保存到硬盘 或通过网络发送给从节点，因此线上建议开启。

RDB 的优点:Redis 加载 RDB 恢复数据远远快于 AOF 的方式。

RDB 的缺点: 没办法做到实时持久化/秒级持久化。使用特定二进制格式保存，新老版本 Redis 不兼容。

### AOF

**AOF(append only file)**：

以独立日志的方式记录每次写命令，重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用是解决了数据持久化的实时性。

开启 AOF 功能需要设置配置：appendonly yes，默认不开启。

工作流程：命令写入（append）、文件同步（sync）、文件重写（rewrite）、重启加载（load）

![[Pasted image 20231018002336.png]]

1）**所有的写入命令会追加到 aof_buf（缓冲区）中。** 2）AOF 缓冲区根据对应的策略向硬盘做同步操作。（一般是由另一个线程执行缓冲区写入磁盘） 3）随着 AOF 文件越来越大，**需要定期对 AOF 文件进行重写**，达到压缩 的目的。（重写需要 fork 出一个子进程） 4）当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。

**AOF 缓冲区同步文件策略：**

![[Pasted image 20231018002402.png]]

everysec 是默认配置，也是建议的同步策略。

linux 的 write 和 fsync 命令含义：

write 写入页缓冲区后直接返回，同步磁盘的操作依赖于系统调度机制。

fsync 针对单个文件操作（比如 AOF 文件），做强制硬盘同步，fsync 将**阻塞**直到写入硬盘完成后返回，保证了数据持久化。

**AOF 重写：**

把 Redis 进程内的数据转化为写命令同步到新 AOF 文件。降低了磁盘空间占用，而且文件小了可以更快被 Redis 加载。

![[Pasted image 20231018002422.png]]

1）执行 AOF 重写请求。如果当前进程正在执行 AOF 重写，请求不执行。如果当前进程正在执行 bgsave 操作，重写命令延迟到 bgsave 完成之后再执行。 2）父进程执行 fork 创建子进程，开销等同于 bgsave 过程。 3.1）主进程 fork 操作完成后，继续响应其他命令。所有修改命令依然写入 AOF 缓冲区并根据 appendfsync 策略同步到硬盘，保证原有 AOF 机制正确性。（这一步好像不是 fork 出来的子进程做的，图似乎有问题？） 3.2）**由于 fork 操作运用写时复制技术（copy-on-write），子进程只能共享 fork 操作时的内存数据。**由于父进程依然响应命令，Redis 使用“**AOF 重写缓冲区**”保存这部分新数据，**防止新 AOF 文件生成期间丢失这部分数据**。 4）子进程根据内存快照，按照命令合并规则写入到新的 AOF 文件。每次批量写入硬盘数据量由配置 aof-rewrite-incremental-fsync 控制，默认为 32MB，防止单次刷盘数据过多造成硬盘阻塞。 5.1）新 AOF 文件写入完成后，子进程发送信号给父进程，父进程更新统计信息，具体见 info persistence 下的 aof_* 相关统计。 5.2）父进程把 AOF 重写缓冲区的数据写入到新的 AOF 文件。 5.3）使用新 AOF 文件替换老文件，完成 AOF 重写。

重写缓冲区要记住，重写 aof 过程中数据库新增的写入变化在重写缓冲区中保存，等新的 aof 生成完毕后合并到新的 aof 文件，保证不丢失 aof 文件生成期间数据库新增的这些数据。

**重启加载：**

aof 开启**优先 aof**，aof 关闭或 aof 文件不存在时候加载 rdb 文件。

**AOF 日志追加阻塞：**

aof 常用的同步硬盘的策略是 everysec，用于平衡性能和数据安全性。Redis 使用另一条线程每秒执行 fsync 同步硬盘。**当系统硬盘资源繁忙时，会造成 Redis 主线程阻塞。**

![[Pasted image 20231018002541.png]]

阻塞流程分析： 1）主线程负责写入 AOF 缓冲区。

2）AOF 线程负责每秒执行一次同步磁盘操作，并记录最近一次同步时间。 3）主线程负责对比上次 AOF 同步时间： ·如果距上次同步成功时间在 2 秒内，主线程直接返回。 ·如果距上次同步成功时间超过 2 秒，主线程将会阻塞，直到同步操作完 成。 通过对 AOF 阻塞流程可以发现两个问题： 1）**everysec 配置最多可能丢失 2 秒数据，不是 1 秒。** 2）如果系统 fsync 缓慢，将会导致 Redis 主线程阻塞影响效率。

## 内存优化

### 字符串优化

Redis 没有采用原生 C 语言的字符串类型而是自己实现了字符串结构，内部简单动态字符串（**simple dynamic string，SDS**）

![[Pasted image 20231018002558.png]]

Redis 自身实现的字符串结构有如下特点： O（1）时间复杂度获取：字符串长度、已用长度、未用长度。 可用于保存字节数组，支持安全的二进制数据存储。 内部实现空间预分配机制，降低内存再分配次数。 惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留。

### 编码优化

![[Pasted image 20231018002618.png]]

编码类型转换在 Redis 写入数据时自动完成，这个转换过程是不可逆的，转换规则只能从小内存编码向大内存编码转换。

## 主从复制

psync 命令完成主从数据同步，同步过程分为：**全量复制和部分复制**。

psync 命令运行需要以下组件支持：

- 主从节点各自**复制偏移量。**（主从节点通过偏移量来检查当前数据是否一致）

![[Pasted image 20231018002637.png]]

- **主节点复制积压缓冲区**。

    复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为 1MB，当主节点有连接的从节点（slave）时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。

    ![[Pasted image 20231018002656.png]]

- **主节点运行 id**。

    每个 Redis 节点启动后都会动态分配一个 40 位的十六进制字符串作为运行 ID。运行 ID 的主要作用是用来唯一识别 Redis 节点，比如从节点保存主节点的运行 ID 识别自己正在复制的是哪个主节点。

### 全量复制

主从第一次复制时，全量复制。

![[Pasted image 20231018002717.png]]

1）发送 psync 命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行 ID，所以发送 psync-1。 2）主节点根据 psync-1 解析出当前为全量复制，回复 +FULLRESYNC 响应。 3）从节点接收主节点的响应数据保存运行 ID 和偏移量 offset。

4）主节点执行 bgsave 保存 RDB 文件到本地。

5）主节点发送 RDB 文件给从节点，从节点把接收的 RDB 文件保存在本地并直接作为从节点的数据文件。

6）对于从节点开始接收 RDB 快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在**复制客户端缓冲区**（跟上文所说主节点复制积压缓冲区不是一个东西）内，当从节点加载完 RDB 文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性。如果主节点创建和传输 RDB 的时间过长，对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。

7）从节点接收完主节点传送来的全部数据后会清空自身旧数据。

8）从节点清空数据后开始加载 RDB 文件。

9）从节点成功加载完 RDB 后，如果当前节点开启了 AOF 持久化功能，它会立刻做 bgrewriteaof 操作，为了保证全量复制后 AOF 持久化文件立刻可用。

### 部分复制

当从节点（slave）正在复制主节点（master）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求**补发丢失的命令数据**，如果**主节点的复制积压缓冲区内**存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。

简单说就是由于一些故障，复制连接断了，从节点重新跟主节点连接后，要求补发丢了的命令数据，如果主节点的复制积压缓冲区内还存在这些数据，就能部分复制，恢复正常，没有或者有一部分已经不在缓冲区里了，就不行了。

![[Pasted image 20231018002737.png]]

1）当主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障并中断复制连接。

2）主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。

3）当主从节点网络恢复后，从节点会再次连上主节点

4）当主从连接恢复后，由于从节点之前保存了自身已复制的**偏移量**和**主节点的运行 ID**。因此会把它们当作 psync 参数发送给主节点，要求进行部分复制操作。

5）主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前主节点；之后**根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +CONTINUE 响应，表示可以进行部分复制**。

6）主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。

## 哨兵模式 Redis Sentinel

Redis Sentinel 是一个分布式架构，其中**包含若干个 Sentinel 节点和 Redis 数据节点**，每个 Sentinel 节点会对数据节点和其余 Sentinel 节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他 Sentinel 节点进行“协商”，当大多数 Sentinel 节点都认为主节点不可达时，它们会**选举**出一个 Sentinel 节点来完成自动故障转移的工作，同时会将这个变化实时通知给 Redis 应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了 Redis 的高可用问题。

Redis Sentinel 与 Redis 主从复制模式只是多了若干 Sentinel 节点，所以 Redis Sentinel 并没有针对 Redis 节点做了特殊处理。

部署至少三个且奇数个的 Sentinel 节点。 3 个以上是通过增加 Sentinel 节点的个数提高对于故障判定的准确性，因 为领导者选举需要至少一半加 1 个节点，奇数个节点可以在满足该条件的基 础上节省一个节点。

### 实现原理

三个定时任务（获取主从结构、获取其他哨兵节点的信息以及其他哨兵节点对主节点的判断信息、对其他哨兵和所有主从节点的连通性测试）

- 每隔 10 秒，**每个 Sentinel 节点会向主节点和从节点**发送 info 命令获取最新的拓扑结构（更新主从信息）

![[Pasted image 20231018002755.png]]

- 每隔 2 秒，每个 Sentinel 节点会向 Redis 数据节点的 __sentinel__：hello 频道上发送该 Sentinel 节点对于**主节点的判断以及当前 Sentinel 节点的信息**，同时每个 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及它们对主节点的判断（哨兵节点互相之间信息交换：**发现新的 Sentinel 节点、交换主节点的状态**- 作为后面客观下线以及领导者选举的依据）

![[Pasted image 20231018002816.png]]

- 每隔 1 秒，每个 Sentinel 节点会向主节点、从节点、其余 Sentinel 节点发送一条 ping 命令做一次心跳检测，来确认这些节点当前是否可达

![[Pasted image 20231018002836.png]]

主观下线和客观下线

- **主观下线：**（当前哨兵一家之言）第三个定时任务，每个 Sentinel 节点会每隔 1 秒对主节点、从节点、其他 Sentinel 节点发送 ping 命令做心跳检测，当这些节点超过 down-after-milliseconds 没有进行有效回复，Sentinel 节点就会对该节点做失败判定。

![[Pasted image 20231018002937.png]]

- **客观下线：**大部分 Sentinel 节点都对主节点的下线做了同意的判定。当 Sentinel 主观下线的节点是**主节点**时，该Sentinel节点会通过sentinel is-master-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断，当超过<quorum>个数，Sentinel 节点认为主节点确实有问题，这时该 Sentinel 节点会做出客观下线的决定。

![[Pasted image 20231018003021.png]]

sentinel monitor <master-name> <ip> <port> **<quorum>** 命令，设置哨兵

![[Pasted image 20231018003059.png]]

Sentinel 领导者选举

Sentinel 节点对于主节点已经做了客观下线后：

1. 每个在线的 Sentinel 节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他 Sentinel 节点发送 sentinel is-master-down-by-addr 命令，要求将自己设置为领导者。
2. 收到命令的 Sentinel 节点，如果没有同意过其他 Sentinel 节点的 sentinel is-master-down-by-addr 命令，将同意该请求，否则拒绝。
3. 如果该 Sentinel 节点发现自己的票数已经大于等于 max（quorum，num（sentinels）/2+1），那么它将成为领导者。
4. 如果此过程没有选举出领导者，将进入下一次选举。

**总结就是**：哨兵确认主节点客观下线后，向其他哨兵发请求告诉它们我要成为领导者。每个哨兵只能投票一次，别的哨兵跟自己要票时，会直接给投票给来要票的哨兵，也就是说谁先跟自己要票，就给谁投票。当哨兵发现自己获得票数已经大于等于 **max**（quorum，num（sentinels）/2+1），成为领导者，整个选举直接结束。

**故障转移**

领导者选举出的 Sentinel 节点负责故障转移，具体步骤如下： 1）在从节点列表中选出一个节点作为新的主节点，选择方法如下：

![[Pasted image 20231018003158.png]]

2）Sentinel 领导者节点会对第一步选出来的从节点执行 slaveof no one 命 令让其成为主节点。 3）Sentinel 领导者节点会向剩余的从节点发送命令，让它们成为新主节 点的从节点，复制规则和 parallel-syncs 参数有关。 4）Sentinel 节点集合会将原来的主节点更新为从节点，并保持着对其关 注，当其恢复后命令它去复制新的主节点。

## 集群 Redis Cluster

使用虚拟槽分区的数据分布理论。

16384 个槽，0~16383。

cluster 模式下会存在操作限制：key 批量操作（mget）只能批量同一个 slot 上的 key；事务只能操作同一个节点上的多 key；无法将 list 等映射到不同节点；只有一个 db0，而不是 16 个；主从复制结构只有一层。

### 节点通信

Gossip 协议。

![[Pasted image 20231018003213.png]]

**meet** 通知新节点加入。

**ping**